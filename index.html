<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
      ExpanDyGauss: Expanding the Viewpoint of Dynamic Scenes beyond Constrained
      Camera Motions
    </title>
    <style>
      body {
        font-family: Arial, sans-serif;
        max-width: 1200px;
        margin: 0 auto;
        padding: 20px;
        line-height: 1.6;
        color: #333;
      }
      .container {
        text-align: center;
      }
      h1 {
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 10px;
        color: #333;
      }
      h2 {
        font-size: 1.8rem;
        margin-bottom: 20px;
      }
      .authors {
        font-size: 1.2rem;
        margin: 20px 0;
        line-height: 1.8;
      }
      .affiliations {
        font-size: 1rem;
        margin-bottom: 10px;
      }
      .notes {
        font-size: 0.9rem;
        margin-bottom: 20px;
      }
      .buttons {
        display: flex;
        justify-content: center;
        gap: 15px;
        margin: 30px 0;
        flex-wrap: wrap;
      }
      .button {
        display: inline-block;
        background-color: #333;
        color: white;
        padding: 10px 20px;
        text-decoration: none;
        border-radius: 5px;
        font-weight: bold;
      }
      .button:hover {
        background-color: #555;
      }
      .tagline {
        font-size: 1.2rem;
        margin: 40px auto;
        max-width: 800px;
        text-align: center;
        line-height: 1.8;
      }
      sup {
        font-size: 0.7em;
        vertical-align: super;
      }
      .author-name {
        color: #0366d6;
      }
      .abstract {
        text-align: justify;
        font-family: Arial, sans-serif;
        font-size: 1rem;
        margin: 40px auto;
        max-width: 800px;
      }
      .abstract h3 {
        font-size: 1.8rem;
        font-weight: bold;
        margin-bottom: 10px;
      }
      .abstract p {
        line-height: 1.8;
      }
      .results {
        text-align: justify;
        font-family: Arial, sans-serif;
        font-size: 1rem;
        margin: 40px auto;
        max-width: 800px;
      }
      .results h3 {
        font-size: 1.8rem;
        font-weight: bold;
        margin-bottom: 10px;
      }
      .results p {
        line-height: 1.8;
      }
      .syndm {
        text-align: justify;
        font-family: Arial, sans-serif;
        font-size: 1rem;
        margin: 40px auto;
        max-width: 800px;
      }
      .syndm h3 {
        font-size: 1.8rem;
        font-weight: bold;
        margin-bottom: 10px;
      }
      .syndm p {
        line-height: 1.8;
      }
      .diagram-container {
        margin: 40px auto;
        max-width: 800px;
        text-align: center;
      }
    </style>
  </head>
  <body>
    <header
      style="
        text-align: center;
        padding: 40px 0 30px 0;
        background-color: #bf0000;
        color: white;
        display: flex;
        flex-direction: column;
        align-items: center;
        gap: 10px;
      "
    >
      <img
        alt="ACLab Logo"
        src="assets/aclab.png"
        style="max-width: 400px; margin-bottom: 10px"
      />

      <h1
        style="
          font-size: 2.2rem;
          font-weight: bold;
          margin: 10px 60px 0 60px;
          color: white;
        "
      >
        ExpanDyGauss: Expanding the Viewpoint of Dynamic Scenes beyond
        Constrained Camera Motions
      </h1>
      <h2 style="font-size: 1.5rem; margin: 10px 0 0 0; color: white">
        BMVC 2025
      </h2>
      <div style="font-size: 1.1rem; margin: 18px 0 0 0; color: white">
        <span style="color: white; font-weight: bold"
          >Le Jiang<sup>1*</sup></span
        >,
        <span style="color: white; font-weight: bold"
          >Shaotong Zhu<sup>1*</sup></span
        >,
        <span style="color: white; font-weight: bold"
          >Yedi Luo<sup>1*</sup></span
        >,
        <span style="color: white; font-weight: bold"
          >Sarah Ostadabbas<sup>1‚Ä†</sup></span
        >,
        <span style="color: white; font-weight: bold"
          >Shayda Moezzi<sup>1</sup></span
        >
      </div>
      <div style="font-size: 1rem; margin: 5px 0 0 0; color: white">
        <sup>1</sup>Northeastern University
      </div>
      <div style="font-size: 0.9rem; margin: 5px 0 0 0; color: white">
        <sup>*</sup> Contribute equally. &nbsp;&nbsp; <sup>‚Ä†</sup>Corresponding
        author.
      </div>
    </header>
    <div class="container">
      <div class="buttons">
        <a href="https://openreview.net/pdf?id=L3DxhwXKZk" class="button"
          >üìÑ Paper(Arxiv)</a
        >
        <!-- <a href="#" class="button">üìù OpenReview</a> -->
        <a href="#" class="button">üé¨ Video [coming soon]</a>
        <a href="#" class="button">üíª Code and data</a>
      </div>

      <div class="tagline">
        <p>
          Given a casually captured monocular video ,<br />
          ExpanDyGauss is able to learn a dynamic Gaussian Splatting model for
          novel-view synthesis
        </p>
      </div>

      <div class="video-container">
        <video controls autoplay loop muted width="100%">
          <source src="assets/figure1.mp4" type="video/mp4" />
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="abstract">
        <h3>Abstract:</h3>
        <p>
          In the area of dynamic Gaussian Splatting for novel view synthesis,
          current state-of-the-art (SOTA) approaches often produce unstable and
          unrealistic results when the camera pose deviates significantly from
          the primary viewpoint. This paper introduces Expanded Dynamic Gaussian
          Splatting (ExpanDyGauss), a monocular Gaussian Splatting method
          designed to handle novel view synthesis under large-angle rotations.
          To address the challenge of insufficient supervision from deviate
          viewpoints across 360 degrees, ExpanDyGauss leverages a video-to-video
          diffusion model to perform inpainting across space and time,
          generating spatial-temporally consistent pseudo ground truth from the
          available training data. This enhanced supervision enables more
          effective optimization of the Gaussian Splatting model, leading to
          realistic scene reconstructions even from challenging viewpoints. We
          further introduce the Synthetic Dynamic Multiview (SynDM) dataset‚Äîthe
          first GTA V-based dynamic multiview dataset specifically constructed
          to evaluate robust dynamic reconstructions from significantly shifted
          camera views. Our method is evaluated both quantitatively and
          qualitatively on SynDM and the widely used NVIDIA dataset, showing
          that ExpanDyGauss outperforms existing SOTA methods for dynamic scene
          reconstruction.
        </p>
      </div>

      <div class="diagram-container">
        <img
          src="assets/diagram.png"
          alt="ExpanDyGauss Framework"
          style="
            width: 100%;
            max-width: 800px;
            margin: 40px auto;
            display: block;
          "
        />
        <p
          style="
            text-align: justify;
            margin-top: 10px;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
            line-height: 1.8;
          "
        >
          <strong>Figure 1:</strong> Overview of our ExpanDyGauss framework.
          Given a monocular video input, our method first extracts dynamic
          Gaussian features and estimates camera poses. Then, through our novel
          pseudo ground truth optimization strategy, we optimize the density and
          color features to enable large-angle novel view synthesis. The final
          output allows free viewpoint rendering with 360 degrees view angle
          changes. Our method consists of several key components: (1) SAM
          segmentation for foreground-background separation, (2) Dynamic
          Gaussian feature extraction for both foreground and background
          elements, (3) Initial Gaussian prediction through given camera
          trajectory, and (4) FLUX inpainting enhancement to supervise the
          gaussian splatting model optimization.
        </p>
      </div>

      <div class="results">
        <h3>Demo on Synthesis Data</h3>
        <p>
          A demo of the results on SynDM dataset. For a monocular input video
          with dynamic scene, our method can generate a dynamic Gaussian
          Splatting model and synthesize novel views.
        </p>
      </div>
      <div class="video-container">
        <video controls autoplay loop muted width="80%">
          <source src="assets/presentvideo.mp4" type="video/mp4" />
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="results">
        <h3>Demo on Real-world Data</h3>
        <p>
          To demonstrate the effectiveness of our method in the real world
          application, we applied our method on a casually captured monocular
          video, and the results are shown below. As the results show, our
          method can generate a dynamic Gaussian Splatting model for reasonable
          synthesize novel view renderings.
        </p>
      </div>
      <div class="video-container">
        <video controls autoplay loop muted width="80%">
          <source src="assets/presentvideo2.mp4" type="video/mp4" />
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="syndm">
        <h3>SynDM dataset</h3>
        <p>
          The Synthetic Dynamic Multiview (SynDM) dataset is the first GTA
          V-based dynamic multiview dataset designed specifically for evaluating
          robust dynamic reconstruction from significantly shifted views. It
          provides a comprehensive benchmark for testing novel view synthesis
          methods under challenging conditions.
        </p>
      </div>

      <div class="video-container">
        <video controls autoplay loop muted width="100%">
          <source src="assets/figure3.mp4" type="video/mp4" />
          Your browser does not support the video tag.
        </video>
      </div>
    </div>
  </body>
</html>
